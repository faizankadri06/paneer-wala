import numpy as np
import tensorflow as tf
from tensorflow import keras

# Load the IMDB dataset
(train_data, train_labels), (test_data, test_labels) = keras.datasets.imdb.load_data(num_words=10000)

# Preprocess the data
word_index = keras.datasets.imdb.get_word_index()

# Define a function to convert the integers back to words
def decode_review(text):
    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])
    decoded_text = ' '.join([reverse_word_index.get(i - 3, '?') for i in text])
    return decoded_text

# Decode and print a sample review
print(decode_review(train_data[0]))

# Pad the sequences to have the same length
train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=0, padding='post', maxlen=256)
test_data = keras.preprocessing.sequence.pad_sequences(test_data, value=0, padding='post', maxlen=256)

# Create the model
model = keras.models.Sequential()
model.add(keras.layers.Embedding(10000, 16))
model.add(keras.layers.GlobalAveragePooling1D())
model.add(keras.layers.Dense(16, activation='relu'))
model.add(keras.layers.Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(train_data, train_labels, epochs=10, batch_size=512, validation_data=(test_data, test_labels))

# Evaluate the model
loss, accuracy = model.evaluate(test_data, test_labels)
print("Test Loss:", loss)
print("Test Accuracy:", accuracy)

